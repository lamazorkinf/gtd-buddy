import OpenAI from "openai"
import type { ProcessedTaskData, ProcessedIntent, ConversationContext } from "@/types/whatsapp"
import type { GTDCategory } from "@/types/task"

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

/**
 * Descarga audio desde Evolution API (maneja audios encriptados de WhatsApp)
 * @param messageId ID del mensaje
 * @param remoteJid JID del remitente
 * @returns Buffer con el audio desencriptado
 */
async function downloadAudioFromEvolution(messageId: string, remoteJid: string): Promise<Buffer> {
  const evolutionUrl = process.env.EVOLUTION_API_URL
  const instanceName = process.env.EVOLUTION_INSTANCE_NAME
  const apiKey = process.env.EVOLUTION_API_KEY

  if (!evolutionUrl || !instanceName || !apiKey) {
    throw new Error("Configuraci√≥n de Evolution API incompleta")
  }

  // Probar diferentes endpoints de Evolution API
  const possibleEndpoints = [
    `${evolutionUrl}/chat/getBase64FromMediaMessage/${instanceName}`,
    `${evolutionUrl}/message/downloadMedia/${instanceName}`,
    `${evolutionUrl}/chat/downloadMedia/${instanceName}`,
  ]

  console.log("üì• Descargando audio desde Evolution API...")

  let lastError: Error | null = null

  for (const url of possibleEndpoints) {
    try {
      console.log("üîç Probando endpoint:", url)

      const response = await fetch(url, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "apikey": apiKey,
        },
        body: JSON.stringify({
          message: {
            key: {
              id: messageId,
              remoteJid: remoteJid,
            }
          }
        })
      })

      if (response.ok) {
        const data = await response.json()

        // Evolution API puede devolver el audio en base64 con diferentes campos
        const base64Data = data.base64 || data.mediaBase64 || data.base64Media || data.media?.base64

        if (base64Data) {
          const buffer = Buffer.from(base64Data, 'base64')
          console.log("‚úÖ Audio descargado desde Evolution API, tama√±o:", buffer.length, "bytes")
          return buffer
        }

        console.log("‚ö†Ô∏è Respuesta recibida pero sin base64:", Object.keys(data))
      } else {
        console.log(`‚ùå Endpoint fall√≥ con ${response.status}: ${response.statusText}`)
      }
    } catch (error: any) {
      console.log(`‚ùå Error en endpoint: ${error.message}`)
      lastError = error
    }
  }

  throw new Error(`No se pudo descargar audio desde Evolution API. √öltimo error: ${lastError?.message || "Ning√∫n endpoint funcion√≥"}`)
}

/**
 * Transcribe un archivo de audio usando Whisper API
 * @param audioUrl URL del archivo de audio (puede estar encriptado)
 * @param messageId ID del mensaje (para descargar desde Evolution API)
 * @param remoteJid JID del remitente
 * @returns Texto transcrito
 */
export async function transcribeAudio(audioUrl: string, messageId?: string, remoteJid?: string): Promise<string> {
  try {
    let audioBuffer: Buffer
    let mimeType = "audio/ogg"

    // Si el audio est√° encriptado (.enc), usar Evolution API para descargarlo
    if (audioUrl.includes('.enc') && messageId && remoteJid) {
      console.log("üîê Audio encriptado detectado, usando Evolution API...")
      audioBuffer = await downloadAudioFromEvolution(messageId, remoteJid)
    } else {
      // Descargar audio directamente
      console.log("üé§ Descargando audio desde:", audioUrl)
      const response = await fetch(audioUrl)

      if (!response.ok) {
        console.error("‚ùå Error descargando audio:", response.status, response.statusText)
        throw new Error(`Error descargando audio: ${response.statusText}`)
      }

      const arrayBuffer = await response.arrayBuffer()
      audioBuffer = Buffer.from(arrayBuffer)
      mimeType = response.headers.get("content-type") || "audio/ogg"
    }

    console.log("üì¶ Audio listo para transcripci√≥n, tama√±o:", audioBuffer.length, "bytes")

    // Crear blob y file
    const audioBlob = new Blob([audioBuffer], { type: mimeType })
    const audioFile = new File([audioBlob], "audio.ogg", { type: mimeType })

    // Transcribir con Whisper
    console.log("ü§ñ Enviando a Whisper para transcripci√≥n...")
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: "whisper-1",
      language: "es", // Espa√±ol
    })

    console.log("‚úÖ Audio transcrito:", transcription.text.substring(0, 100) + "...")
    return transcription.text
  } catch (error: any) {
    console.error("‚ùå Error transcribiendo audio:", {
      message: error?.message,
      status: error?.response?.status,
      data: error?.response?.data
    })
    throw new Error(`No se pudo transcribir el audio: ${error?.message || "Error desconocido"}`)
  }
}

/**
 * Detecta la intenci√≥n del usuario y procesa el mensaje en consecuencia
 * @param text Texto del mensaje
 * @param conversationContext Contexto de la conversaci√≥n (mensajes previos, √∫ltima tarea, etc.)
 * @returns Intenci√≥n procesada con par√°metros
 */
export async function detectUserIntent(
  text: string,
  conversationContext?: Partial<ConversationContext>
): Promise<ProcessedIntent> {
  try {
    const systemPrompt = `Eres un asistente experto en el m√©todo GTD que analiza mensajes de WhatsApp para detectar la intenci√≥n del usuario.

INTENCIONES POSIBLES:
1. "create_task" - El usuario quiere crear una tarea nueva
   Ejemplos: "Llamar al dentista ma√±ana", "Comprar leche"

2. "view_tasks" - El usuario quiere ver sus tareas
   Ejemplos: "mu√©strame mis tareas", "qu√© tengo para hoy", "inbox", "/hoy", "/pr√≥ximas"
   Par√°metros: taskFilter puede ser "inbox", "today", "next_actions", "all"

3. "complete_task" - El usuario quiere marcar una tarea como completada
   Ejemplos: "complet√© esa tarea", "ya hice eso", "marcar como hecha"
   needsContext: true (requiere saber cu√°l fue la √∫ltima tarea)

4. "edit_task" - El usuario quiere editar una tarea
   Ejemplos:
   - "cambiar la fecha a ma√±ana"
   - "modificar el t√≠tulo a Llamar al doctor"
   - "cambiar la descripci√≥n"
   - "mover a pasado ma√±ana"
   - "cambiar el contexto a @casa"
   needsContext: true (requiere saber cu√°l tarea editar)
   Par√°metros:
   - editField: "title" | "description" | "dueDate" | "context" | "category"
   - editValue: nuevo valor (puede ser una fecha relativa como "ma√±ana", "pasado ma√±ana")

5. "add_context" - El usuario quiere agregar contexto a la √∫ltima tarea
   Ejemplos: "agregar eso a @Vilma", "poner esa tarea en @casa", "a√±adir contexto @oficina"
   needsContext: true (requiere saber cu√°l fue la √∫ltima tarea)
   Par√°metros: contextName (sin el @)

6. "help" - El usuario pide ayuda o el men√∫
   Ejemplos: "ayuda", "help", "menu", "qu√© puedes hacer"

7. "greeting" - Saludo o conversaci√≥n casual
   Ejemplos: "hola", "gracias", "ok", "dale"

IMPORTANTE:
- Si el mensaje es una tarea nueva clara, usa "create_task" y analiza la tarea completa
- Si el usuario menciona "la tarea anterior", "esa tarea", "la √∫ltima", necesita contexto (needsContext: true)
- Si el usuario dice "agregar a @contexto" o "poner en @lugar", es "add_context"
- Los comandos como /inbox, /hoy, /pr√≥ximas son "view_tasks"
- S√© conservador: ante la duda sobre crear tarea vs otra intenci√≥n, elige la otra intenci√≥n

CATEGORIZACI√ìN GTD AUTOM√ÅTICA (para create_task):
‚úÖ Si tiene fecha/hora ‚Üí "Pr√≥ximas acciones"
‚úÖ Si espera a otros/respuesta ‚Üí "A la espera"
‚úÖ Si es proyecto grande/m√∫ltiples pasos ‚Üí "Multitarea"
‚úÖ Si es idea/recomendaci√≥n sin urgencia (leer libro, ver pel√≠cula, investigar) ‚Üí "Alg√∫n d√≠a"
‚úÖ Si hay duda ‚Üí "Inbox"

Ejemplos de categorizaci√≥n:
- "Llamar al dentista ma√±ana" ‚Üí Pr√≥ximas acciones (tiene fecha)
- "Esperar respuesta de Juan" ‚Üí A la espera (depende de otro)
- "Organizar evento de fin de a√±o" ‚Üí Multitarea (proyecto grande)
- "Me recomendaron leer El Principito" ‚Üí Alg√∫n d√≠a (recomendaci√≥n sin urgencia)
- "Comprar algo" ‚Üí Inbox (muy vago)

Responde SOLO con JSON v√°lido, sin markdown.`

    const historyContext = conversationContext?.conversationHistory
      ?.slice(-3) // √öltimos 3 mensajes
      .map(msg => `${msg.role === 'user' ? 'Usuario' : 'Asistente'}: ${msg.content}`)
      .join('\n') || 'Sin historial previo'

    const lastTaskInfo = conversationContext?.lastTaskId
      ? `√öltima tarea creada/mencionada: ID ${conversationContext.lastTaskId}`
      : 'Sin tareas previas en esta conversaci√≥n'

    // Obtener fecha actual en Argentina
    const now = new Date()
    const todayInArgentina = now.toLocaleDateString('es-AR', {
      timeZone: 'America/Argentina/Buenos_Aires',
      year: 'numeric',
      month: '2-digit',
      day: '2-digit'
    }).split('/').reverse().join('-')

    const tomorrowInArgentina = new Date(Date.now() + 86400000).toLocaleDateString('es-AR', {
      timeZone: 'America/Argentina/Buenos_Aires',
      year: 'numeric',
      month: '2-digit',
      day: '2-digit'
    }).split('/').reverse().join('-')

    const dayAfterTomorrowInArgentina = new Date(Date.now() + 172800000).toLocaleDateString('es-AR', {
      timeZone: 'America/Argentina/Buenos_Aires',
      year: 'numeric',
      month: '2-digit',
      day: '2-digit'
    }).split('/').reverse().join('-')

    const userPrompt = `HOY ES: ${todayInArgentina} (YYYY-MM-DD)

IMPORTANTE: Para fechas relativas, usa:
- "ma√±ana" = ${tomorrowInArgentina}
- "pasado ma√±ana" = ${dayAfterTomorrowInArgentina}

Contexto de conversaci√≥n:
${historyContext}

${lastTaskInfo}

Mensaje actual del usuario:
"${text}"

Responde con JSON en este formato:
{
  "intent": "create_task" | "view_tasks" | "complete_task" | "edit_task" | "add_context" | "help" | "greeting",
  "confidence": number (0.0 a 1.0),
  "needsContext": boolean (true si requiere saber la tarea previa),
  "parameters": {
    "taskFilter": "inbox" | "today" | "next_actions" | "all" (solo para view_tasks),
    "contextName": "string sin @" (solo para add_context o edit_task cuando editField es "context"),
    "editField": "title" | "description" | "dueDate" | "context" | "category" (solo para edit_task),
    "editValue": "string o YYYY-MM-DD para fechas" (solo para edit_task),
    "category": "Inbox | Pr√≥ximas acciones | Multitarea | A la espera | Alg√∫n d√≠a" (solo para edit_task cuando editField es "category")
  },
  "taskData": {
    // Solo si intent es "create_task", incluir an√°lisis completo de la tarea
    "isTask": true,
    "title": "string",
    "description": "string opcional",
    "contextName": "string opcional sin @",
    "dueDate": "YYYY-MM-DD opcional (DEBE SER 2025 o posterior)",
    "estimatedMinutes": number opcional,
    "category": "Inbox | Pr√≥ximas acciones | Multitarea | A la espera | Alg√∫n d√≠a",
    "isQuickAction": boolean,
    "confidence": number
  }
}`

    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      temperature: 0.2,
      response_format: { type: "json_object" },
    })

    const responseText = completion.choices[0].message.content
    if (!responseText) {
      throw new Error("No se recibi√≥ respuesta de OpenAI")
    }

    console.log("ü§ñ Respuesta raw de OpenAI (detectUserIntent):", responseText)
    const parsed = JSON.parse(responseText)
    console.log("üìä Intent parseado:", JSON.stringify(parsed, null, 2))

    // Parsear taskData si existe
    let taskData: ProcessedTaskData | undefined
    if (parsed.taskData && parsed.intent === "create_task") {
      let dueDateObj: Date | undefined = undefined
      if (parsed.taskData.dueDate) {
        console.log("üìÖ Procesando fecha en detectUserIntent:", parsed.taskData.dueDate)
        const [year, month, day] = parsed.taskData.dueDate.split('-').map(Number)
        console.log("üìÖ Componentes parseados:", { year, month, day })
        dueDateObj = new Date(Date.UTC(year, month - 1, day, 23 + 3, 59, 0))
        console.log("üìÖ Date object creado:", dueDateObj.toISOString())
        console.log("üìÖ Fecha legible AR:", dueDateObj.toLocaleDateString('es-AR', { timeZone: 'America/Argentina/Buenos_Aires' }))
      }

      taskData = {
        isTask: true,
        title: parsed.taskData.title?.substring(0, 80) || text.substring(0, 80),
        description: parsed.taskData.description || undefined,
        contextName: parsed.taskData.contextName || undefined,
        dueDate: dueDateObj,
        estimatedMinutes: parsed.taskData.estimatedMinutes || undefined,
        category: (parsed.taskData.category as GTDCategory) || "Inbox",
        isQuickAction: parsed.taskData.isQuickAction || false,
        confidence: parsed.taskData.confidence || 0.5,
      }
    }

    const result: ProcessedIntent = {
      intent: parsed.intent,
      confidence: parsed.confidence || 0.5,
      needsContext: parsed.needsContext || false,
      parameters: parsed.parameters || {},
      taskData,
    }

    return result
  } catch (error) {
    console.error("Error detectando intenci√≥n:", error)

    // Fallback: intentar crear tarea
    return {
      intent: "create_task",
      confidence: 0.1,
      taskData: {
        isTask: true,
        title: text.substring(0, 80),
        description: text.length > 80 ? text : undefined,
        category: "Inbox",
        isQuickAction: false,
        confidence: 0.1,
      },
    }
  }
}
