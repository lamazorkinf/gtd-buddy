import OpenAI from "openai"
import type { ProcessedTaskData } from "@/types/whatsapp"
import type { GTDCategory } from "@/types/task"

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

/**
 * Descarga audio desde Evolution API (maneja audios encriptados de WhatsApp)
 * @param messageId ID del mensaje
 * @param remoteJid JID del remitente
 * @returns Buffer con el audio desencriptado
 */
async function downloadAudioFromEvolution(messageId: string, remoteJid: string): Promise<Buffer> {
  const evolutionUrl = process.env.EVOLUTION_API_URL
  const instanceName = process.env.EVOLUTION_INSTANCE_NAME
  const apiKey = process.env.EVOLUTION_API_KEY

  if (!evolutionUrl || !instanceName || !apiKey) {
    throw new Error("Configuraci√≥n de Evolution API incompleta")
  }

  const url = `${evolutionUrl}/message/download/${instanceName}`

  console.log("üì• Descargando audio desde Evolution API...")

  const response = await fetch(url, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "apikey": apiKey,
    },
    body: JSON.stringify({
      key: {
        id: messageId,
        remoteJid: remoteJid,
      }
    })
  })

  if (!response.ok) {
    throw new Error(`Error descargando desde Evolution API: ${response.statusText}`)
  }

  const data = await response.json()

  // Evolution API devuelve el audio en base64
  if (data.base64) {
    const buffer = Buffer.from(data.base64, 'base64')
    console.log("‚úÖ Audio descargado desde Evolution API, tama√±o:", buffer.length, "bytes")
    return buffer
  }

  throw new Error("Evolution API no devolvi√≥ el audio en formato esperado")
}

/**
 * Transcribe un archivo de audio usando Whisper API
 * @param audioUrl URL del archivo de audio (puede estar encriptado)
 * @param messageId ID del mensaje (para descargar desde Evolution API)
 * @param remoteJid JID del remitente
 * @returns Texto transcrito
 */
export async function transcribeAudio(audioUrl: string, messageId?: string, remoteJid?: string): Promise<string> {
  try {
    let audioBuffer: Buffer
    let mimeType = "audio/ogg"

    // Si el audio est√° encriptado (.enc), usar Evolution API para descargarlo
    if (audioUrl.includes('.enc') && messageId && remoteJid) {
      console.log("üîê Audio encriptado detectado, usando Evolution API...")
      audioBuffer = await downloadAudioFromEvolution(messageId, remoteJid)
    } else {
      // Descargar audio directamente
      console.log("üé§ Descargando audio desde:", audioUrl)
      const response = await fetch(audioUrl)

      if (!response.ok) {
        console.error("‚ùå Error descargando audio:", response.status, response.statusText)
        throw new Error(`Error descargando audio: ${response.statusText}`)
      }

      const arrayBuffer = await response.arrayBuffer()
      audioBuffer = Buffer.from(arrayBuffer)
      mimeType = response.headers.get("content-type") || "audio/ogg"
    }

    console.log("üì¶ Audio listo para transcripci√≥n, tama√±o:", audioBuffer.length, "bytes")

    // Crear blob y file
    const audioBlob = new Blob([audioBuffer], { type: mimeType })
    const audioFile = new File([audioBlob], "audio.ogg", { type: mimeType })

    // Transcribir con Whisper
    console.log("ü§ñ Enviando a Whisper para transcripci√≥n...")
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: "whisper-1",
      language: "es", // Espa√±ol
    })

    console.log("‚úÖ Audio transcrito:", transcription.text.substring(0, 100) + "...")
    return transcription.text
  } catch (error: any) {
    console.error("‚ùå Error transcribiendo audio:", {
      message: error?.message,
      status: error?.response?.status,
      data: error?.response?.data
    })
    throw new Error(`No se pudo transcribir el audio: ${error?.message || "Error desconocido"}`)
  }
}

/**
 * Analiza un texto usando GPT-4 para extraer informaci√≥n de tarea GTD
 * @param text Texto a analizar (puede ser transcripci√≥n de audio o texto directo)
 * @returns Datos de tarea procesados
 */
export async function analyzeTaskText(text: string): Promise<ProcessedTaskData> {
  try {
    const systemPrompt = `Eres un asistente experto en el m√©todo GTD (Getting Things Done).
Tu trabajo es analizar mensajes de texto y extraer informaci√≥n estructurada para crear tareas.

Categor√≠as GTD disponibles:
- "Inbox": Tareas que a√∫n no se han procesado (por defecto para capturas r√°pidas)
- "Pr√≥ximas acciones": Acciones concretas que se pueden hacer ahora
- "Multitarea": Proyectos que requieren m√∫ltiples pasos
- "A la espera": Tareas que dependen de alguien m√°s
- "Alg√∫n d√≠a": Ideas o tareas para el futuro

Contextos comunes: @casa, @oficina, @llamadas, @compras, @computadora, @recados, @reuniones, @email

Regla de 2 minutos: Si la tarea toma menos de 2 minutos, marca isQuickAction como true.

Analiza el siguiente texto y extrae:
1. T√≠tulo conciso de la tarea (m√°ximo 80 caracteres)
2. Descripci√≥n detallada (si hay informaci√≥n adicional)
3. Contexto sugerido (si se menciona o se puede inferir)
4. Fecha de vencimiento (si se menciona "ma√±ana", "pr√≥ximo lunes", "en 3 d√≠as", etc.)
5. Tiempo estimado en minutos (si se menciona)
6. Categor√≠a GTD m√°s apropiada
7. Si aplica la regla de 2 minutos

IMPORTANTE:
- Para capturas r√°pidas sin procesar, usa siempre "Inbox"
- Solo usa otras categor√≠as si el usuario especifica claramente el tipo de tarea
- Las fechas relativas deben calcularse desde hoy
- S√© conservador con la clasificaci√≥n: ante la duda, usa "Inbox"

Responde SOLO con un JSON v√°lido, sin markdown ni explicaciones adicionales.`

    const userPrompt = `Fecha de hoy: ${new Date().toISOString().split("T")[0]}

Texto a analizar:
"${text}"

Responde con JSON en este formato:
{
  "title": "string (m√°ximo 80 caracteres)",
  "description": "string (opcional, m√°s detalles)",
  "contextName": "string (opcional, sin @)",
  "dueDate": "YYYY-MM-DD (opcional)",
  "estimatedMinutes": number (opcional),
  "category": "Inbox | Pr√≥ximas acciones | Multitarea | A la espera | Alg√∫n d√≠a",
  "isQuickAction": boolean,
  "confidence": number (0.0 a 1.0, qu√© tan seguro est√°s del an√°lisis)
}`

    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      temperature: 0.3, // Baja temperatura para respuestas m√°s consistentes
      response_format: { type: "json_object" },
    })

    const responseText = completion.choices[0].message.content
    if (!responseText) {
      throw new Error("No se recibi√≥ respuesta de OpenAI")
    }

    const parsed = JSON.parse(responseText)

    // Validar y construir objeto ProcessedTaskData
    const processedData: ProcessedTaskData = {
      title: parsed.title.substring(0, 80), // Asegurar l√≠mite de caracteres
      description: parsed.description || undefined,
      contextName: parsed.contextName || undefined,
      dueDate: parsed.dueDate ? new Date(parsed.dueDate) : undefined,
      estimatedMinutes: parsed.estimatedMinutes || undefined,
      category: (parsed.category as GTDCategory) || "Inbox",
      isQuickAction: parsed.isQuickAction || false,
      confidence: parsed.confidence || 0.5,
    }

    return processedData
  } catch (error) {
    console.error("Error analizando texto con GPT-4:", error)

    // Fallback: crear tarea b√°sica en Inbox
    return {
      title: text.substring(0, 80),
      description: text.length > 80 ? text : undefined,
      category: "Inbox",
      isQuickAction: false,
      confidence: 0.1, // Baja confianza en el fallback
    }
  }
}

/**
 * Procesa un mensaje de WhatsApp: transcribe audio si es necesario y analiza el texto
 * @param text Texto del mensaje (si es texto directo)
 * @param audioUrl URL del audio (si es nota de voz)
 * @param messageId ID del mensaje (para descargar audio encriptado)
 * @param remoteJid JID del remitente (para descargar audio encriptado)
 * @returns Datos de tarea procesados
 */
export async function processWhatsAppMessage(
  text?: string,
  audioUrl?: string,
  messageId?: string,
  remoteJid?: string
): Promise<ProcessedTaskData> {
  let finalText = text || ""

  // Si es audio, primero transcribir
  if (audioUrl) {
    finalText = await transcribeAudio(audioUrl, messageId, remoteJid)
  }

  if (!finalText.trim()) {
    throw new Error("No se pudo obtener texto del mensaje")
  }

  // Analizar el texto con GPT-4
  return await analyzeTaskText(finalText)
}
